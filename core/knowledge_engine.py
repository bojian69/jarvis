#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“å¼•æ“ - æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
"""

import logging
from typing import List, Dict, Optional
from .document_processor import DocumentProcessor
from .vector_manager import VectorManager
from .query_engine import QueryEngine
from models.llm_interface import LLMInterface

class KnowledgeEngine:
    def __init__(self, config: Dict):
        self.config = config
        self.doc_processor = DocumentProcessor(config)
        self.vector_manager = VectorManager(config)
        self.query_engine = QueryEngine(config)
        self.llm = LLMInterface(config)
        
        logging.info("çŸ¥è¯†åº“å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def add_document(self, file_path: str, doc_type: str) -> Dict:
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        try:
            # 1. å¤„ç†æ–‡æ¡£
            doc_data = self.doc_processor.process_document(file_path, doc_type)
            
            # 2. å‘é‡åŒ–å­˜å‚¨
            result = self.vector_manager.add_document(doc_data)
            
            return {"success": True, "doc_id": result["doc_id"]}
        except Exception as e:
            logging.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    def query(self, question: str, top_k: int = 5) -> Dict:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        try:
            # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å…ƒæŸ¥è¯¢ï¼ˆå…³äºçŸ¥è¯†åº“æœ¬èº«çš„é—®é¢˜ï¼‰
            meta_result = self.handle_meta_query(question)
            if meta_result:
                return meta_result
            
            # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
            docs = self.query_engine.search(question, top_k)
            
            # 2. ç”Ÿæˆå›ç­”
            answer = self.llm.generate_answer(question, docs)
            
            # 3. å‡†å¤‡æ¥æºä¿¡æ¯ï¼ŒæŒ‰æ–‡æ¡£åˆ†ç»„
            sources_by_doc = {}
            for doc in docs:
                source = doc["source"]
                if source not in sources_by_doc:
                    sources_by_doc[source] = {
                        "source": source,
                        "content": doc["content"][:150],
                        "score": doc.get("score", 0)
                    }
                else:
                    # å¦‚æœåŒä¸€æ–‡æ¡£æœ‰å¤šä¸ªç‰‡æ®µï¼Œåˆå¹¶å†…å®¹
                    existing_content = sources_by_doc[source]["content"]
                    new_content = doc["content"][:150]
                    if new_content not in existing_content:
                        sources_by_doc[source]["content"] = existing_content + "..." + new_content
            
            return {
                "answer": answer,
                "sources": list(sources_by_doc.values())[:3]  # æœ€å¤šæ˜¾ç¤º3ä¸ªä¸åŒæ–‡æ¡£çš„æ¥æº
            }
        except Exception as e:
            logging.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
            return {"answer": "æŸ¥è¯¢å‡ºé”™ï¼Œè¯·ç¨åé‡è¯•", "sources": []}
    
    def get_stats(self) -> Dict:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡"""
        return self.vector_manager.get_stats()
    
    def list_documents(self) -> List[Dict]:
        """åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£"""
        return self.vector_manager.list_documents()
    
    def handle_meta_query(self, question: str) -> Dict:
        """å¤„ç†å…ƒæŸ¥è¯¢ï¼ˆå…³äºçŸ¥è¯†åº“æœ¬èº«çš„é—®é¢˜ï¼‰"""
        question_lower = question.lower()
        
        # æ£€æµ‹æ˜¯å¦æ˜¯å…³äºçŸ¥è¯†åº“çš„é—®é¢˜
        meta_keywords = ['çŸ¥è¯†åº“', 'æ–‡æ¡£', 'æœ‰å“ªäº›', 'åŒ…å«', 'å­˜å‚¨', 'ä¸Šä¼ ', 'ç»Ÿè®¡']
        if any(keyword in question_lower for keyword in meta_keywords):
            stats = self.get_stats()
            documents = self.list_documents()
            
            if stats.get('document_count', 0) == 0:
                answer = """## ğŸ“ çŸ¥è¯†åº“çŠ¶æ€

ç›®å‰çŸ¥è¯†åº“ä¸º **ç©º**ï¼Œæ²¡æœ‰ä¸Šä¼ ä»»ä½•æ–‡æ¡£ã€‚

### ğŸ“ å¦‚ä½•ä½¿ç”¨
1. **ä¸Šä¼ æ–‡æ¡£**: ç‚¹å‡»ä¸Šæ–¹çš„â€œä¸Šä¼ æ–‡æ¡£â€æŒ‰é’®
2. **æ”¯æŒæ ¼å¼**: PDFã€Markdown (.md) æ–‡ä»¶
3. **å¼€å§‹æé—®**: ä¸Šä¼ åå³å¯åŸºäºæ–‡æ¡£å†…å®¹æé—®

### âœ¨ åŠŸèƒ½ç‰¹æ€§
- ğŸ” **æ™ºèƒ½æ£€ç´¢**: åŸºäºè¯­ä¹‰çš„æ–‡æ¡£æœç´¢
- ğŸ¤– **AIé—®ç­”**: ç»“åˆå¤šä¸ªæ–‡æ¡£ç‰‡æ®µç»¼åˆå›ç­”
- ğŸ“Š **Markdownæ”¯æŒ**: ä¸°å¯Œçš„æ ¼å¼åŒ–å±•ç¤º"""
            else:
                answer_parts = [f"## ğŸ“ çŸ¥è¯†åº“æ¦‚è§ˆ\n"]
                answer_parts.append(f"ğŸ“Š **ç»Ÿè®¡ä¿¡æ¯**")
                answer_parts.append(f"- æ–‡æ¡£æ•°é‡: **{stats['document_count']}** ä¸ª")
                answer_parts.append(f"- æ–‡æœ¬ç‰‡æ®µ: **{stats['total_chunks']}** ä¸ª\n")
                
                answer_parts.append("ğŸ“„ **å·²ä¸Šä¼ æ–‡æ¡£**")
                for i, doc in enumerate(documents, 1):
                    doc_type_icon = "ğŸ“" if doc['type'] == 'markdown' else "ğŸ“°"
                    answer_parts.append(f"{i}. {doc_type_icon} **{doc['filename']}**")
                    answer_parts.append(f"   - ç±»å‹: {doc['type'].upper()}")
                    answer_parts.append(f"   - ç‰‡æ®µ: {doc['chunks']} ä¸ª")
                    answer_parts.append(f"   - é¢„è§ˆ: {doc['sample_content']}\n")
                
                answer_parts.append("ğŸ’¡ **ä½¿ç”¨å»ºè®®**")
                answer_parts.append("- å¯ä»¥é’ˆå¯¹ä»¥ä¸Šæ–‡æ¡£å†…å®¹æé—®")
                answer_parts.append("- ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶ç»¼åˆå›ç­”")
                
                answer = '\n'.join(answer_parts)
            
            return {
                "answer": answer,
                "sources": [{"source": "çŸ¥è¯†åº“ç³»ç»Ÿ", "content": "ç³»ç»Ÿå†…ç½®ä¿¡æ¯"}]
            }
        
        return None