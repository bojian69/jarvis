# ğŸ¤– Jarvis AI çŸ¥è¯†åº“éƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- **Python**: 3.8+
- **å†…å­˜**: æœ€ä½4GBï¼Œæ¨è8GB+
- **å­˜å‚¨**: 10GB+ å¯ç”¨ç©ºé—´
- **æ“ä½œç³»ç»Ÿ**: macOS/Linux/Windows

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd jarvis

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)
python -m venv venv
source venv/bin/activate  # Linux/macOS
# æˆ– venv\Scripts\activate  # Windows
```

### 2. å®‰è£…Pythonä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£…ç¥ç»ç½‘ç»œåµŒå…¥æ¨¡å‹ (å…³é”®!)
pip install sentence-transformers

# å¯é€‰ï¼šå®‰è£…GPUæ”¯æŒ (å¦‚æœ‰NVIDIA GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 3. ğŸ§  ç¥ç»ç½‘ç»œåµŒå…¥æ¨¡å‹é…ç½®

#### è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ (æ¨è)
```bash
# é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½å¤šè¯­è¨€åµŒå…¥æ¨¡å‹
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')"
```

#### æ‰‹åŠ¨é…ç½®æ¨¡å‹
```python
# config/settings.py ä¸­é…ç½®
MODEL_CONFIG = {
    # åµŒå…¥æ¨¡å‹é€‰æ‹© (å½±å“æ£€ç´¢ç²¾åº¦)
    "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",  # å¤šè¯­è¨€æ”¯æŒ
    # "embedding_model": "all-MiniLM-L6-v2",  # è‹±æ–‡ä¼˜åŒ–
    # "embedding_model": "distiluse-base-multilingual-cased",  # é«˜ç²¾åº¦
}
```

#### åµŒå…¥æ¨¡å‹é€‰æ‹©æŒ‡å—

| æ¨¡å‹åç§° | è¯­è¨€æ”¯æŒ | ç²¾åº¦ | é€Ÿåº¦ | å†…å­˜å ç”¨ | æ¨èåœºæ™¯ |
|---------|----------|------|------|----------|----------|
| `paraphrase-multilingual-MiniLM-L12-v2` | ä¸­è‹±æ–‡ | é«˜ | å¿« | 420MB | **æ¨è** |
| `all-MiniLM-L6-v2` | è‹±æ–‡ | ä¸­ | å¾ˆå¿« | 80MB | è‹±æ–‡æ–‡æ¡£ |
| `distiluse-base-multilingual-cased` | å¤šè¯­è¨€ | å¾ˆé«˜ | ä¸­ | 480MB | é«˜ç²¾åº¦éœ€æ±‚ |
| `paraphrase-multilingual-mpnet-base-v2` | å¤šè¯­è¨€ | æœ€é«˜ | æ…¢ | 1.1GB | æœ€ä½³æ•ˆæœ |

### 4. ğŸ¦™ æœ¬åœ°LLMé…ç½® (å¯é€‰)

#### å®‰è£…Ollama
```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows: ä¸‹è½½å®‰è£…åŒ…
# https://ollama.ai/download
```

#### ä¸‹è½½æ¨èæ¨¡å‹
```bash
# ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹ (æ¨è)
ollama pull qwen2.5:7b

# è½»é‡çº§é€‰æ‹©
ollama pull qwen2.5:1.5b

# è‹±æ–‡ä¼˜åŒ–
ollama pull llama3.1:8b
```

#### å¯åŠ¨OllamaæœåŠ¡
```bash
# å¯åŠ¨æœåŠ¡
ollama serve

# éªŒè¯æœåŠ¡
curl http://localhost:11434/api/tags
```

### 5. ğŸ“ å­˜å‚¨ç»“æ„åˆå§‹åŒ–

```bash
# è¿è¡Œåˆå§‹åŒ–è„šæœ¬
python scripts/init_storage.py

# æˆ–æ‰‹åŠ¨åˆ›å»ºç›®å½•
mkdir -p /Volumes/common/jarvis/{documents/{pdf,markdown},vector_db,uploads,cache}
```

**å­˜å‚¨ç»“æ„**:
```
/Volumes/common/jarvis/  # å¯è‡ªå®šä¹‰è·¯å¾„
â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ pdf/            # PDFæ–‡æ¡£å­˜å‚¨
â”‚   â”œâ”€â”€ markdown/       # Markdownæ–‡æ¡£å­˜å‚¨
â”‚   â””â”€â”€ raw/           # åŸå§‹æ–‡æ¡£å¤‡ä»½
â”œâ”€â”€ vector_db/         # ChromaDBå‘é‡æ•°æ®åº“
â”œâ”€â”€ uploads/           # ä¸´æ—¶ä¸Šä¼ ç›®å½•
â””â”€â”€ cache/            # ç¼“å­˜æ–‡ä»¶
```

### 6. âš™ï¸ é…ç½®æ–‡ä»¶è®¾ç½®

ç¼–è¾‘ `config/settings.py`:

```python
# å­˜å‚¨è·¯å¾„é…ç½®
STORAGE_CONFIG = {
    "documents_path": "/Volumes/common/jarvis/documents",
    "vector_db_path": "/Volumes/common/jarvis/vector_db",
    "uploads_path": "/Volumes/common/jarvis/uploads",
}

# æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    # LLMé…ç½® (å¯é€‰)
    "llm_url": "http://localhost:11434",
    "llm_model": "qwen2.5:7b",
    
    # åµŒå…¥æ¨¡å‹é…ç½® (å¿…éœ€)
    "embedding_model": "paraphrase-multilingual-MiniLM-L12-v2",
    "embedding_dim": 384,
}

# æ£€ç´¢é…ç½®
SEARCH_CONFIG = {
    "relevance_threshold": 0.35,  # ç›¸å…³æ€§é˜ˆå€¼
    "max_results": 5,           # æœ€å¤§è¿”å›ç»“æœ
    "keyword_weight": 0.3,      # å…³é”®è¯æƒé‡
}
```

### 7. ğŸš€ å¯åŠ¨æœåŠ¡

```bash
# å¯åŠ¨Jarvis AI
python app.py

# æˆ–ä½¿ç”¨å¼€å‘æ¨¡å¼
FLASK_ENV=development python app.py
```

**è®¿é—®åœ°å€**:
- æœ¬åœ°: http://localhost:8080
- å±€åŸŸç½‘: http://[your-ip]:8080

## ğŸ”§ é«˜çº§é…ç½®

### GPUåŠ é€Ÿ (å¯é€‰)

å¦‚æœæœ‰NVIDIA GPUï¼Œå¯ä»¥å¯ç”¨GPUåŠ é€Ÿï¼š

```bash
# å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# éªŒè¯GPUå¯ç”¨æ€§
python -c "import torch; print(torch.cuda.is_available())"
```

### æ¨¡å‹ç¼“å­˜é…ç½®

```python
# è®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•
import os
os.environ['TRANSFORMERS_CACHE'] = '/path/to/model/cache'
os.environ['HF_HOME'] = '/path/to/huggingface/cache'
```

### æ€§èƒ½ä¼˜åŒ–

```python
# config/settings.py
PERFORMANCE_CONFIG = {
    "batch_size": 32,           # æ‰¹å¤„ç†å¤§å°
    "max_seq_length": 512,     # æœ€å¤§åºåˆ—é•¿åº¦
    "num_threads": 4,          # çº¿ç¨‹æ•°
    "enable_gpu": True,        # å¯ç”¨GPU
}
```

## ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”

### åµŒå…¥æ¨¡å‹æ€§èƒ½

| æŒ‡æ ‡ | MiniLM-L12 | MiniLM-L6 | MPNet-Base |
|------|------------|-----------|------------|
| ç²¾åº¦ | 85% | 82% | 88% |
| é€Ÿåº¦ | å¿« | å¾ˆå¿« | ä¸­ç­‰ |
| å†…å­˜ | 420MB | 80MB | 1.1GB |
| å¤šè¯­è¨€ | âœ… | âŒ | âœ… |

### LLMæ¨¡å‹é€‰æ‹©

| å†…å­˜è¦æ±‚ | æ¨èæ¨¡å‹ | ç‰¹ç‚¹ | ä¸‹è½½å¤§å° |
|----------|----------|------|----------|
| 4GB | qwen2.5:1.5b | è½»é‡å¿«é€Ÿ | 1.5GB |
| 8GB | qwen2.5:7b | **æ¨èå¹³è¡¡** | 4.1GB |
| 16GB+ | qwen2.5:14b | é«˜è´¨é‡ | 8.2GB |

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. åµŒå…¥æ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
# æ‰‹åŠ¨ä¸‹è½½
wget https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/pytorch_model.bin

# æˆ–ä½¿ç”¨é•œåƒæº
export HF_ENDPOINT=https://hf-mirror.com
```

#### 2. å†…å­˜ä¸è¶³
```python
# å‡å°‘æ‰¹å¤„ç†å¤§å°
MODEL_CONFIG["batch_size"] = 16

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
MODEL_CONFIG["embedding_model"] = "all-MiniLM-L6-v2"
```

#### 3. æ£€ç´¢ç²¾åº¦ä½
```python
# é™ä½ç›¸å…³æ€§é˜ˆå€¼
SEARCH_CONFIG["relevance_threshold"] = 0.2

# å¢åŠ è¿”å›ç»“æœæ•°
SEARCH_CONFIG["max_results"] = 10
```

#### 4. ç«¯å£å ç”¨
```bash
# æŸ¥çœ‹ç«¯å£å ç”¨
lsof -i :8080

# ä¿®æ”¹ç«¯å£
export PORT=8081
python app.py
```

### éªŒè¯å®‰è£…

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
python test_embedding.py
python test_knowledge_status.py

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8080/stats
```

## ğŸ“š ä½¿ç”¨æŒ‡å—

### 1. æ–‡æ¡£ä¸Šä¼ 
- æ”¯æŒæ ¼å¼: PDF, Markdown (.md)
- æ”¯æŒæ‰¹é‡ä¸Šä¼ å’Œæ–‡ä»¶å¤¹ä¸Šä¼ 
- è‡ªåŠ¨æ–‡æœ¬æå–å’Œå‘é‡åŒ–

### 2. æ™ºèƒ½é—®ç­”
- åŸºäºè¯­ä¹‰æ£€ç´¢çš„ç²¾å‡†åŒ¹é…
- æ”¯æŒä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢
- Markdownæ ¼å¼å›ç­”å±•ç¤º

### 3. çŸ¥è¯†åº“ç®¡ç†
- å®æ—¶æŸ¥çœ‹æ–‡æ¡£ç»Ÿè®¡
- æ”¯æŒæ–‡æ¡£åˆ é™¤å’Œæ›´æ–°
- å‘é‡æ•°æ®åº“ç®¡ç†å·¥å…·

---

**ğŸ¯ éƒ¨ç½²å®Œæˆåï¼Œæ‚¨å°†æ‹¥æœ‰ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„æœ¬åœ°AIçŸ¥è¯†åº“ç³»ç»Ÿï¼**

**ğŸ“ æŠ€æœ¯æ”¯æŒ**: å¦‚é‡é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ `logs/jarvis.log` æˆ–æäº¤Issueã€‚